name: roberta-base
arch: mlm
pretrained_name: roberta-base
context_length: 512
tokenizer: ${.pretrained_name}
specialise:
  epochs: auto
  lr: auto
  weight_decay: 0.01
  warmup_ratio: auto
  scheduler: auto
  gradient_clip: 1.0
  freeze_embeddings: false
